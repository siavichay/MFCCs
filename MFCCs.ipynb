{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Procesamiento de habla para Learning Machine:</center>\n",
    "# Mel-Frecuency Ceptral Coefficients (MFCCs)\n",
    "\n",
    "El reconocimiento de habla  hoy en día es una herramienta muy utilizada para la interacción con la tecnología en general, desde el ámbito de entretenimiento al ámbito profesional.\n",
    "\n",
    "Metodología:\n",
    "Para que una máquina logre identificar un sonido hablado, es necesario entender el cómo los seres humanos decodificamos los sonidos hablados.\n",
    "\n",
    "MFCCs: en base a lo anterior, los MFCCs por lo tanto representan con presición este fin. Actualmente son muy utilizados para el reconocimiento del habla. \n",
    "\n",
    "A continuación se presenta el código necesario para obtener los MFCCs de la base de datos <a href=\"https://link.springer.com/article/10.1007/s10579-015-9324-5\">KALAKA3</a>\n",
    "\n",
    "## Pasos para la creación de MFCCs\n",
    "1. Organización del dataset\n",
    "2. Lectura y obtención de MFCCs\n",
    "    - i. Obtención de las señales en Numpy Arrays\n",
    "    - ii. Separar la señal de audio en frames.\n",
    "    - iii. Cálculo del periodograma estimado de la potencia de la señal\n",
    "    - iv. Aplicar el filtro mel, sumar la energía en cada filtro\n",
    "    - v. Obtención del logaritmo de las energías del filterbank\n",
    "    - vi. Obtención de la DCT\n",
    "    - vii.Guardar los coeficientes (2-13) de la DCT, descartar lo demás\n",
    "3. Creación de la red de entrenamiento\n",
    "4. Análisis de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Organización del dataset\n",
    "En primer lugar es necesario organizar el dataset de la siguiente manera:\n",
    "- KALAKA3\n",
    "    - DEV_KALAKA3\n",
    "    - EVAL_KALAKA3\\eval\\data\n",
    "    - TRAIN_KALAKA3\\data\n",
    "        - Basque\n",
    "            - clean\n",
    "            - noisy\n",
    "        - ....\n",
    "            ....\n",
    "        - Spanish\n",
    "            - clean\n",
    "            - noisy\n",
    "                - 0a7707a3.wav\n",
    "                - ...\n",
    "                - ff5e57c3.wav\n",
    "                \n",
    "### Carga de librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file includes routines for basic signal processing including framing and computing power spectra.\n",
    "# Author: James Lyons 2012\n",
    "import decimal\n",
    "import numpy\n",
    "import math\n",
    "import logging\n",
    "import os\n",
    "from scipy.fftpack import dct\n",
    "from scipy.io.wavfile import read as readwav\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificación de Paths\n",
    "Esta sección es muy importante para que el método de creación de los MFCCs pueda iterar de manera correcta, tanto para la lecutra de los audios, como para el grabado de los MFCCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SOURCE = 'KALAKA3' \n",
    "OUTPUT = 'MFCCS'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file includes routines for basic signal processing including framing and computing power spectra.\n",
    "# Author: James Lyons 2012\n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "\n",
    "def rolling_window(a, window, step=1):\n",
    "    # http://ellisvalentiner.com/post/2017-03-21-np-strides-trick\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
    "\n",
    "\n",
    "def framesig(sig, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,)), stride_trick=True):\n",
    "    \"\"\"Frame a signal into overlapping frames.\n",
    "    :param sig: the audio signal to frame.\n",
    "    :param frame_len: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n",
    "    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n",
    "    \"\"\"\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step))\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = numpy.zeros((padlen - slen,))\n",
    "    padsignal = numpy.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
    "    else:\n",
    "        indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "            numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "        indices = numpy.array(indices, dtype=numpy.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "\n",
    "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,))):\n",
    "    \"\"\"Does overlap-add procedure to undo the action of framesig.\n",
    "    :param frames: the array of frames.\n",
    "    :param siglen: the length of the desired signal, use 0 if unknown. Output will be truncated to siglen samples.\n",
    "    :param frame_len: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :returns: a 1-D signal.\n",
    "    \"\"\"\n",
    "    frame_len = round_half_up(frame_len)\n",
    "    frame_step = round_half_up(frame_step)\n",
    "    numframes = numpy.shape(frames)[0]\n",
    "    assert numpy.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
    "\n",
    "    indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "        numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "    indices = numpy.array(indices, dtype=numpy.int32)\n",
    "    padlen = (numframes - 1) * frame_step + frame_len\n",
    "\n",
    "    if siglen <= 0: siglen = padlen\n",
    "\n",
    "    rec_signal = numpy.zeros((padlen,))\n",
    "    window_correction = numpy.zeros((padlen,))\n",
    "    win = winfunc(frame_len)\n",
    "\n",
    "    for i in range(0, numframes):\n",
    "        window_correction[indices[i, :]] = window_correction[\n",
    "                                               indices[i, :]] + win + 1e-15  # add a little bit so it is never zero\n",
    "        rec_signal[indices[i, :]] = rec_signal[indices[i, :]] + frames[i, :]\n",
    "\n",
    "    rec_signal = rec_signal / window_correction\n",
    "    return rec_signal[0:siglen]\n",
    "\n",
    "\n",
    "def magspec(frames, NFFT):\n",
    "    \"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    if numpy.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            numpy.shape(frames)[1], NFFT)\n",
    "    complex_spec = numpy.fft.rfft(frames, NFFT)\n",
    "    return numpy.absolute(complex_spec)\n",
    "\n",
    "\n",
    "def powspec(frames, NFFT):\n",
    "    \"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    return 1.0 / NFFT * numpy.square(magspec(frames, NFFT))\n",
    "\n",
    "\n",
    "def logpowspec(frames, NFFT, norm=1):\n",
    "    \"\"\"Compute the log power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :param norm: If norm=1, the log power spectrum is normalised so that the max value (across all frames) is 0.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the log power spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    ps = powspec(frames, NFFT);\n",
    "    ps[ps <= 1e-30] = 1e-30\n",
    "    lps = 10 * numpy.log10(ps)\n",
    "    if norm:\n",
    "        return lps - numpy.max(lps)\n",
    "    else:\n",
    "        return lps\n",
    "\n",
    "\n",
    "def preemphasis(signal, coeff=0.95):\n",
    "    \"\"\"perform preemphasis on the input signal.\n",
    "    :param signal: The signal to filter.\n",
    "    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n",
    "    :returns: the filtered signal.\n",
    "    \"\"\"\n",
    "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate filterbank features. Provides e.g. fbank and mfcc features for use in ASR applications\n",
    "# Author: James Lyons 2012\n",
    "\n",
    "def calculate_nfft(samplerate, winlen):\n",
    "    \"\"\"Calculates the FFT size as a power of two greater than or equal to\n",
    "    the number of samples in a single window length.\n",
    "    \n",
    "    Having an FFT less than the window length loses precision by dropping\n",
    "    many of the samples; a longer FFT than the window allows zero-padding\n",
    "    of the FFT buffer which is neutral in terms of frequency domain conversion.\n",
    "    :param samplerate: The sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: The length of the analysis window in seconds.\n",
    "    \"\"\"\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft\n",
    "\n",
    "def mfcc(signal,samplerate=16000,winlen=0.025,winstep=0.01,numcep=13,\n",
    "         nfilt=26,nfft=None,lowfreq=0,highfreq=None,preemph=0.97,ceplifter=22,appendEnergy=True,\n",
    "         winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute MFCC features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param numcep: the number of cepstrum to return, default 13\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is None, which uses the calculate_nfft function to choose the smallest size that does not drop sample data.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n",
    "    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    nfft = nfft or calculate_nfft(samplerate, winlen)\n",
    "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
    "    feat = numpy.log(feat)\n",
    "    feat = dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
    "    feat = lifter(feat,ceplifter)\n",
    "    if appendEnergy: feat[:,0] = numpy.log(energy) # replace first cepstral coefficient with log of frame energy\n",
    "    return feat\n",
    "\n",
    "def fbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "          nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "          winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute Mel-filterbank energy features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n",
    "        second return value is the energy in each frame (total energy, unwindowed)\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    signal = preemphasis(signal,preemph)\n",
    "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
    "    pspec = powspec(frames,nfft)\n",
    "    energy = numpy.sum(pspec,1) # this stores the total energy in each frame\n",
    "    energy = numpy.where(energy == 0,numpy.finfo(float).eps,energy) # if energy is zero, we get problems with log\n",
    "\n",
    "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
    "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
    "    feat = numpy.where(feat == 0,numpy.finfo(float).eps,feat) # if feat is zero, we get problems with log\n",
    "\n",
    "    return feat,energy\n",
    "\n",
    "def logfbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "             nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "             winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute log Mel-filterbank energy features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
    "    return numpy.log(feat)\n",
    "\n",
    "def ssc(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
    "        nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
    "        winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute Spectral Subband Centroid features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    signal = preemphasis(signal,preemph)\n",
    "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
    "    pspec = powspec(frames,nfft)\n",
    "    pspec = numpy.where(pspec == 0,numpy.finfo(float).eps,pspec) # if things are all zeros we get problems\n",
    "\n",
    "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
    "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
    "    R = numpy.tile(numpy.linspace(1,samplerate/2,numpy.size(pspec,1)),(numpy.size(pspec,0),1))\n",
    "\n",
    "    return numpy.dot(pspec*R,fb.T) / feat\n",
    "\n",
    "def hz2mel(hz):\n",
    "    \"\"\"Convert a value in Hertz to Mels\n",
    "    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 2595 * numpy.log10(1+hz/700.)\n",
    "\n",
    "def mel2hz(mel):\n",
    "    \"\"\"Convert a value in Mels to Hertz\n",
    "    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n",
    "    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n",
    "    \"\"\"\n",
    "    return 700*(10**(mel/2595.0)-1)\n",
    "\n",
    "def get_filterbanks(nfilt=20,nfft=512,samplerate=16000,lowfreq=0,highfreq=None):\n",
    "    \"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n",
    "    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n",
    "    :param nfilt: the number of filters in the filterbank, default 20.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz. Affects mel spacing.\n",
    "    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n",
    "    :param highfreq: highest band edge of mel filters, default samplerate/2\n",
    "    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel(lowfreq)\n",
    "    highmel = hz2mel(highfreq)\n",
    "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    bin = numpy.floor((nfft+1)*mel2hz(melpoints)/samplerate)\n",
    "\n",
    "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bin[j]), int(bin[j+1])):\n",
    "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "    return fbank\n",
    "\n",
    "def lifter(cepstra, L=22):\n",
    "    \"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n",
    "    magnitude of the high frequency DCT coeffs.\n",
    "    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n",
    "    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n",
    "    \"\"\"\n",
    "    if L > 0:\n",
    "        nframes,ncoeff = numpy.shape(cepstra)\n",
    "        n = numpy.arange(ncoeff)\n",
    "        lift = 1 + (L/2.)*numpy.sin(numpy.pi*n/L)\n",
    "        return lift*cepstra\n",
    "    else:\n",
    "        # values of L <= 0, do nothing\n",
    "        return cepstra\n",
    "\n",
    "def delta(feat, N):\n",
    "    \"\"\"Compute delta features from a feature vector sequence.\n",
    "    :param feat: A numpy array of size (NUMFRAMES by number of features) containing features. Each row holds 1 feature vector.\n",
    "    :param N: For each frame, calculate delta features based on preceding and following N frames\n",
    "    :returns: A numpy array of size (NUMFRAMES by number of features) containing delta features. Each row holds 1 delta feature vector.\n",
    "    \"\"\"\n",
    "    if N < 1:\n",
    "        raise ValueError('N must be an integer >= 1')\n",
    "    NUMFRAMES = len(feat)\n",
    "    denominator = 2 * sum([i**2 for i in range(1, N+1)])\n",
    "    delta_feat = numpy.empty_like(feat)\n",
    "    padded = numpy.pad(feat, ((N, N), (0, 0)), mode='edge')   # padded version of feat\n",
    "    for t in range(NUMFRAMES):\n",
    "        delta_feat[t] = numpy.dot(numpy.arange(-N, N+1), padded[t : t+2*N+1]) / denominator   # [t : t+2*N+1] == [(N+t)-N : (N+t)+N+1]\n",
    "    return delta_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotMfcc(filter_banks):\n",
    "    plt.subplot(312)\n",
    "    filter_banks -= (numpy.mean(filter_banks,axis=0) + 1e-8)\n",
    "    plt.imshow(filter_banks.T, cmap=plt.cm.jet, aspect='auto')\n",
    "    plt.xticks(numpy.arange(0, (filter_banks.T).shape[1],\n",
    "    int((filter_banks.T).shape[1] / 4)),\n",
    "    ['0s', '0.5s', '1s', '1.5s','2.5s','3s','3.5'])\n",
    "    ax = plt.gca()\n",
    "    ax.invert_yaxis()\n",
    "    plt.title('the spectrum image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de los MFCCs\n",
    "El siguiente bucle lee y crea los MFCCs desde el SOURCE especificado, luego crea una carpeta con el nombre OUTPUT con la misma estructura del dataset de los archivos de audio (WAVs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "for root, dirs, files in os.walk( SOURCE ):\n",
    "\n",
    "    for archivo in files:\n",
    "        if archivo.endswith('wav'):\n",
    "            output_dir = root.replace( SOURCE, OUTPUT   )\n",
    "            output_filename = archivo.split('.')[0]\n",
    "            if not os.path.exists(output_dir):\n",
    "                os.makedirs(output_dir)\n",
    "\n",
    "            input_path = \"{}/{}\".format( root,archivo ) #DIRECCION DEL ARCHIVO WAV A PROCESAR\n",
    "            output_path = \"{}/{}.mfccs\".format( output_dir, output_filename ) #DIRECCION DONDE SE VA A GUARDAR EL ARCHIVO DE MFCC\n",
    "            print(\"{}: {} {}\".format(i,input_path,output_path))#SE IMPRIME ORIGEN Y DESTINO \n",
    "            i+=1\n",
    "            _, input= readwav(input_path) #SE LEE EL ARCHIVO DE AUDIO Y SE GUARDA COMO UN ARRAY DE NUMPY\n",
    "\n",
    "            output = mfcc( input )\n",
    "            \n",
    "            print(output.shape)\n",
    "            output.tofile( output_path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de los MFCCs para su procesamiento\n",
    "A continuacion se elaborara un metodo para compactar los MFCCs en un archivo csv, que es un poco mas versatil que guardarlo por separado\n",
    "\n",
    "### Construccion del training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basque\n",
      "Catalan\n",
      "English\n",
      "Galician\n",
      "Portuguese\n",
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "# make a new folder in this directory to save our results in\n",
    "\n",
    "TRAINDIR=\"MFCCS/TRAIN_KALAKA3/data\"\n",
    "X_MFCCs=[]\n",
    "Y_MFCCs=[]\n",
    "if not os.path.exists(TRAINDIR):\n",
    "    print(\"No se encuentra ningun MFCC\")\n",
    "    sys.exit()\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "#especificar el numero de wavs a leer\n",
    "numWavs=2\n",
    "#se almacenará en esta variable los mfccs y sus etiquetas\n",
    "for idioma in os.listdir(TRAINDIR):\n",
    "  \n",
    "    sourceMFCC=TRAINDIR+\"/\"+idioma\n",
    "    print(idioma)\n",
    "\n",
    "    for root, dirs, files in os.walk( sourceMFCC):\n",
    "        for archivo in files:\n",
    "            if archivo.endswith('mfccs'): # only get MFCCs \n",
    "                mfccFile = root + \"/\" + os.path.splitext(archivo)[0] + \".mfccs\"\n",
    "                #print(mfccFile)\n",
    "                #Establezco el label del MFCC \n",
    "                mfcc=numpy.fromfile(mfccFile)\n",
    "                mfccFrames=mfcc.reshape(int(mfcc.shape[0]/13),13)\n",
    "                for frame in mfccFrames:\n",
    "                    X_MFCCs.append(frame)#almaceno el MFCC\n",
    "                    Y_MFCCs.append(idioma)#almaceno el idioma al que pertenece el MFCC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basque\n",
      "Catalan\n",
      "English\n",
      "Galician\n",
      "Portuguese\n",
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "# make a new folder in this directory to save our results in\n",
    "\n",
    "TESTDIR=\"MFCCS/TEST_KALAKA3/data\"\n",
    "X_TEST_MFCCs=[]\n",
    "Y_TEST_MFCCs=[]\n",
    "if not os.path.exists(TESTDIR):\n",
    "    print(\"No se encuentra ningun MFCC\")\n",
    "    sys.exit()\n",
    "# get MFCCs for every .wav file in our specified directory \n",
    "#se almacenará en esta variable los mfccs y sus etiquetas\n",
    "for idioma in os.listdir(TESTDIR):\n",
    "  \n",
    "    sourceMFCC=TESTDIR+\"/\"+idioma\n",
    "    print(idioma)\n",
    "\n",
    "    for root, dirs, files in os.walk( sourceMFCC):\n",
    "        for archivo in files:\n",
    "            if archivo.endswith('mfccs'): # only get MFCCs \n",
    "                mfccFile = root + \"/\" + os.path.splitext(archivo)[0] + \".mfccs\"\n",
    "                #print(mfccFile)\n",
    "                #Establezco el label del MFCC \n",
    "                mfcc=numpy.fromfile(mfccFile)\n",
    "                #print(mfcc.shape)\n",
    "                mfccFrames=mfcc.reshape(int(mfcc.shape[0]/13),13)\n",
    "                #print(mfccFrames.shape)\n",
    "                #print(mfccFrames[0])\n",
    "                for frame in mfccFrames:\n",
    "                    X_TEST_MFCCs.append(frame)#almaceno el MFCC\n",
    "                    Y_TEST_MFCCs.append(idioma)#almaceno el idioma al que pertenece el MFCC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obteniendo un mfcc para pruebas\n",
    "mfccTmp=numpy.fromfile(\"MFCCS/TRAIN_KALAKA3/data/Basque\\clean/00248e27.mfccs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#Metodos a utilizar\n",
    "#mfcc\n",
    "#delta\n",
    "#logfbank\n",
    "#Obteniendo el mfcc de un wav para compararlo con el Mfcc anterior\n",
    "import scipy.io.wavfile as wav\n",
    "(rate,sig) = wav.read(\"KALAKA3/TRAIN_KALAKA3/data\\Catalan\\clean/1a8b426c.wav\")\n",
    "print(rate)\n",
    "mfcc_feat = mfcc(sig,rate)\n",
    "d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "fbank_feat = logfbank(sig,rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mfccTmp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-db0b4038576b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmfccFrames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmfccTmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccTmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccTmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccFrames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplotMfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmfccFrames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mfccTmp' is not defined"
     ]
    }
   ],
   "source": [
    "mfccFrames=mfccTmp.reshape(int(mfccTmp.shape[0]/13),13) \n",
    "print(mfccTmp.shape)\n",
    "print(mfccFrames.shape)\n",
    "plotMfcc(mfccFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconicimiento Automático del habla (ASR)\n",
    "### Carga de los mfccs\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se convierten a arrays las listas obtenidas\n",
    "X_MFCCs=numpy.asarray(X_MFCCs)\n",
    "Y_MFCCs=numpy.asarray(Y_MFCCs)\n",
    "X_TEST_MFCCs=numpy.asarray(X_TEST_MFCCs)\n",
    "Y_TEST_MFCCs=numpy.asarray(Y_TEST_MFCCs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'deepacoustics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-312-eb682092a1b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdeepacoustics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_class_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'deepacoustics'"
     ]
    }
   ],
   "source": [
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "#from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from deepacoustics.tf.util import get_class_weights\n",
    "\n",
    "\n",
    "with tf.Session() as sess0:\n",
    "    assert not tf.executing_eagerly()\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_shape=X_MFCCs.shape[1:], activation='tanh'))\n",
    "    model.add(Dense(64, activation='tanh'))\n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    \n",
    "    #model.add(Flatten())\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "\n",
    "    model.add(Dense(30))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    #Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments.\n",
    "    model.summary()\n",
    "  # history = model.fit(x=X_train_array, y=y_train_array, epochs=5, verbose=1, validation_split = 0.33, shuffle=True, class_weight=get_class_weights(pd.Series((list(set(labels))),dtype='category').cat.codes.values),batch_size=batch_size) \n",
    "    history = model.fit(x=X_MFCCs, y=Y_MFCCs, epochs=25, verbose=1, validation_split = 0.1, shuffle=True, class_weight=get_class_weights(pd.Series(Y_MFCCs,dtype='category').cat.codes.values),batch_size=128) \n",
    "    \n",
    "    model_evaluation = model.evaluate(x=X_TEST_MFCCs, y=Y_TEST_MFCCs, batch_size=None, verbose=1)\n",
    "\n",
    "    prediction = model.predict(X_TEST_MFCCs, batch_size = 128, verbose = 1)\n",
    "    \n",
    "    #april_tst = model.predict(mfcc_april_test, batch_size = 128, verbose = 1)\n",
    "\n",
    "    sess0.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = Y_MFCCs.shape[0]\n",
    "\n",
    "def build_model_graph(input_shape=(13,)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_labels))\n",
    "    model.add(Activation('softmax'))\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')    \n",
    "    modelmodel = build_model_graph()\n",
    "    return modelmodel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BaseSession.__del__ at 0x000001EA41E4D048>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 738, in __del__\n",
      "    tf_session.TF_DeleteSession(self._session)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function BaseSession._Callable.__del__ at 0x000001EA41E4DAE8>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1455, in __del__\n",
      "    self._session._session, self._handle, status)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\n",
      "    c_api.TF_GetCode(self.status.status))\n",
      "tensorflow.python.framework.errors_impl.UnimplementedError: ReleaseCallable is not supported for this session.\n"
     ]
    }
   ],
   "source": [
    "filter_size = build_model_graph(input_shape=(13,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 32)                448       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 30)                3870      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30)                0         \n",
      "=================================================================\n",
      "Total params: 14,750\n",
      "Trainable params: 14,750\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_4 to have shape (30,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-304-51e919e63a49>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Display model architecture summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# Calculate pre-training accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_TEST_MFCCs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_TEST_MFCCs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1349\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1350\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1351\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m                 exception_prefix='target')\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m             \u001b[1;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected activation_4 to have shape (30,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "# Display model architecture summary \n",
    "model.summary()# Calculate pre-training accuracy \n",
    "score = model.evaluate(X_TEST_MFCCs, Y_TEST_MFCCs, verbose=2)\n",
    "accuracy = 100*score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "- <a href=\"http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/\">Mel Frequency Cepstral Coefficient (MFCC) tutorial</a> \n",
    "- <a href=\"https://www.researchgate.net/publication/330477843_A_Mel-Filterbank_and_MFCC-based_Neural_Network_Approach_to_Train_the_Houston_Toad_Call_Detection _System_Design\">A Mel-Filterbank and MFCC-based Neural Network Approach to Train the Houston Toad Call Detection System Design </a> \n",
    "- <a href=\"https://towardsdatascience.com/speech-recognition-analysis-f03ff9ce78e9\">Speech Recognition Analysis</a> \n",
    "- <a href=\"https://github.com/rctatman/getMFCCs/blob/master/getMFCCs.py\">getMFCCs</a> \n",
    "- <a href=\"https://towardsdatascience.com/how-to-apply-machine-learning-and-deep-learning-methods-to-audio-analysis-615e286fcbbc\">How to apply machine learning and deep learning methods to audio analysis</a>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
